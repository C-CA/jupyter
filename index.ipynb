{"cells":[{"metadata":{"_cell_guid":"578d0c98-1823-ed78-6e55-498e03ed14fe","trusted":true,"scrolled":true},"cell_type":"code","source":"import pdb\n#Draft last saved 03 Mar 6:22pm\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport matplotlib.pyplot as plt\n\nfrom subprocess import check_output\nfrom datetime import time\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n\n#noon = time_to_seconds(time(12, 0, 0))\n#df.timestamp = df.timestamp.apply(lambda t: abs(noon - t))\n\n# one hot encode categorical columns\n#columns = [\"Geography Description\",]\n#df = pd.get_dummies(df, columns=columns)\n#df.head(10)\n\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/C-CA/keras-demos/main/ppm-on-time-new-data.csv\")\ndf = df.drop(axis=1, labels = [\"Date\"])\ndf = df[['Primary Delay per 100 miles','Footfall','Count of Trains/Timing Points - WTT','Planned','On Time WTT%','PPM%']]\n\n#,'PPM%','Dwell%','Incident Count','Footfall','Planned','Count of Trains/Timing Points - WTT','Station Dwells','Primary Delay Minutes'], )","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"#Shuffle? Sanity test.\n\nshuffle = False\nshuffleLabel = 'On Time WTT%'\nif shuffle:\n    sdf = df[shuffleLabel]\n    df[shuffleLabel] = sdf.sample(frac=1).values","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Extract the training and test data\ndef train():\n    global df, labelname, model, model2, submodels, X, y, X_train, X_test, y_train, y_test, scaler, label_df, temp_data, temp_labels, temp_scaler, temp_model, temp_df\n    \n    df = pd.read_csv(\"https://raw.githubusercontent.com/C-CA/keras-demos/main/ppm-on-time-new-data.csv\")\n    df = df.drop(axis=1, labels = [\"Date\"])\n    df = df[['Primary Delay per 100 miles','Footfall','Count of Trains/Timing Points - WTT','Planned','On Time WTT%','PPM%']]\n    \n    output_columns = list(df.columns[-1:-3:-1])\n    \n    for i, input_variable in enumerate(df.columns[:-2]):\n        if not checkboxes.children[i].value:\n            df.pop(input_variable)    \n    \n    labels = df.pop(buttons.value)\n    output_columns.remove(buttons.value)\n    \n    for unused_output in output_columns:\n        df.pop(unused_output)\n    \n    labelname = labels.name\n\n    #print(df.head())\n    #print(labels.head())\n\n\n    data = df.values\n    labels = labels.values\n\n    X = data  # all rows, no label\n    y = labels  # all rows, label only\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\n    X_unscaled = X_train\n    \n    # Scale the data to be between -1 and 1\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = scaler.transform(X_train)\n    X_test = scaler.transform(X_test)\n\n    # Establish model\n    model = RandomForestRegressor(n_jobs=-1, verbose = 0)\n    model2 = GradientBoostingRegressor(verbose = 0)\n    \n    #Make submodels for sticky inference sliders\n    \n    from sklearn.multioutput import MultiOutputRegressor\n    submodels = {}\n    for input_variable in df.columns:\n        temp_df = df.copy(deep=True)\n        temp_data = temp_df.pop(input_variable)\n        \n        temp_data = temp_data.values.reshape(-1,1)\n        temp_labels = temp_df.values\n        \n        temp_scaler = StandardScaler()\n        #temp_scaler.fit(temp_data)\n        #temp_data = temp_scaler.transform(temp_data)\n        \n        temp_model = MultiOutputRegressor(GradientBoostingRegressor(verbose = 0))\n        #temp_model.set_params(n_estimators=7)\n        temp_model.fit(temp_data, temp_labels)\n        \n        submodels[input_variable] = (temp_model,temp_scaler)\n\n    # Try different numbers of n_estimators - this will take a minute or so\n    if False:\n        estimators = np.arange(1, 500, 10)\n        scores = []\n        for n in estimators:\n            model.set_params(n_estimators=n)\n            model.fit(X_train, y_train)\n            scores.append(model.score(X_test, y_test))\n        plt.title(\"Effect of n_estimators\")\n        plt.xlabel(\"n_estimator\")\n        plt.ylabel(\"score\")\n        plt.plot(estimators, scores)\n\n    model.set_params(n_estimators=70)\n    model.fit(X_train, y_train)\n    model2.fit(X_unscaled, y_train)\n    \n    \n    return model","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"a3ca6b14-dd6b-2f2c-99b7-c6b3db57b755","trusted":true,"scrolled":true},"cell_type":"code","source":"'''\nCross-validate our model using k-fold  cross validation.\n'''\ndef train_and_validate(b):\n    global X, y, mae\n    print('Generating model...')\n    \n    train()\n    \n    from sklearn.model_selection import RepeatedKFold\n    from sklearn.model_selection import cross_val_score\n    from numpy import absolute\n    from numpy import mean\n    from numpy import std\n\n    # define the evaluation procedure\n    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n    # evaluate the model and collect the scores\n    n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, verbose = 0)\n    # force the scores to be positive\n    n_scores = absolute(n_scores)\n    # summarize performance\n    mae = mean(n_scores)\n    \n    #print(model)\n    print(f'Containing variables {list(df.columns)} \\nTargeting {labelname} as output')\n    print(f'Cross-validated mean absolute error for model: {mae*100:.2f}%, standard deviation {std(n_scores):.2f}')\n    \n    inference_widgets()\n\ndef infer(b, printout = True, whichmodel =['RF','GBM']):\n    \n    prediction = np.nan\n    prediction2 = np.nan\n    \n    if 'RF' in whichmodel:\n        prediction = model.predict(scaler.transform(np.array([box.children[1].value for box in inwidgets.children], ndmin = 2)))[0]\n    \n    if 'GBM' in whichmodel:\n        prediction2 = model2.predict(np.array([box.children[1].value for box in inwidgets.children], ndmin = 2))[0]\n    \n    if printout:\n        print([box.children[1].value for box in inwidgets.children])\n        #print(f'{labelname} RF = {prediction*100:.2f}%, GBR = {prediction2*100:.2f}% ')\n        print(f'Predicted a {labelname} of {prediction*100:.2f}%.')\n    \n    else:\n        return {'RF':prediction, 'GBM':prediction2 }\n    \nimport asyncio\n\nclass Timer:\n    def __init__(self, timeout, callback):\n        self._timeout = timeout\n        self._callback = callback\n\n    async def _job(self):\n        await asyncio.sleep(self._timeout)\n        self._callback()\n\n    def start(self):\n        self._task = asyncio.ensure_future(self._job())\n\n    def cancel(self):\n        self._task.cancel()\n\ndef debounce(wait):\n    \"\"\" Decorator that will postpone a function's\n        execution until after `wait` seconds\n        have elapsed since the last time it was invoked. \"\"\"\n    def decorator(fn):\n        timer = None\n        def debounced(*args, **kwargs):\n            nonlocal timer\n            def call_it():\n                fn(*args, **kwargs)\n            if timer is not None:\n                timer.cancel()\n            timer = Timer(wait, call_it)\n            timer.start()\n        return debounced\n    return decorator\n\n    \ndef donothing(*args):\n    pass\n\nimport sys\nfrom copy import copy\n\n@debounce(0.01)\ndef SliderChanged(change):\n    #global p\n    \n    #pdb.set_trace()\n    inference = infer(None, printout = False, whichmodel = 'GBM')\n    #print(f\"\\r{change}\", end=\"\")\n    print(f\"\\r{labelname} live Estimate = {inference['GBM']*100:.2f}%\", end=\"\")\n    \n    if synchrobox.value:\n        mover = change['owner']\n\n        barewidgets2 = copy(barewidgets)\n        barewidgets2.remove(mover)\n        \n        #k = barewidgets.index(mover)\n        \n        for barewidget in barewidgets2:\n            if barewidget!= mover:\n                barewidget.unobserve(SliderChanged, names = 'value')\n\n\n        i = barewidgets.index(mover)\n        name = inwidgets.children[i].children[2].value\n\n        p = submodels[name][0].predict(np.array(mover.value, ndmin = 2))\n        \n\n\n        for j, barewidget in enumerate(barewidgets2):\n            if barewidget != mover:\n                barepred = p[0][j]\n                barechange = barepred - barewidget.value\n\n                #if barepred >= barewidget.value:\n                #if barechange<barewidget.max*0.1:\n                barewidget.value = round(barewidget.value + barechange/8, 2)\n\n                #elif barepred<barewidget.value:\n                #    barewidget.value = barewidget.value - (barewidget.value -barepred)/4\n\n\n\n        for barewidget in barewidgets2:\n            if barewidget!= mover:\n                barewidget.observe(SliderChanged, names = 'value')\n\nfrom copy import copy\nimport sys\n\ndef SliderChangedFuncGenerator(slider):\n    def wrapper(*args):\n        owner = slider\n        for i, barewidget in enumerate(barewidgets):\n            if barewidget is not slider:\n                \n                name = inwidgets.children[i].children[2].value\n                \n                inference_vector = [box.children[1].value for box in inwidgets.children]\n                inference_vector.pop(i)\n                \n                barewidget.value = submodels[name][0].predict(submodels[name][1].transform(np.array(inference_vector, ndmin = 2)))[0]\n                #sys.stdout.flush()\n                print(args, x_widget.value, y_widget.value,  end=\"\\r\", flush=False,)\n                print(f'i={i}')\n    \n    return wrapper","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"if False:\n    np.set_printoptions(precision =2)\n\n    print(y_test[0:10])\n    print(model.predict(X_test[0:10]))\n\n    from sklearn.metrics import mean_absolute_percentage_error\n    mean_absolute_percentage_error(y_test[0:10],model.predict(X_test[0:10]))","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"#Jupyter widgets\n\nfrom IPython.display import display\nimport ipywidgets as widgets\nfrom ipywidgets import Layout, Label, HBox, VBox\n\nlabel_layout = Layout(width='150px',height='21px', font_size = '50px')\nz = Label('Using these variables:',layout=label_layout)\n\n\ncheckboxes = []\n\nfor column in df.columns[:-2]:\n    checkbox = widgets.Checkbox(\n        value=True,\n        description=column,\n        disabled=False,\n        indent=True,\n        layout=Layout(height='18px', padding = '1px')\n    )\n    checkboxes.append(checkbox)\n    \ncheckboxes = VBox(checkboxes)    \n\n\nbuttons = widgets.ToggleButtons(\n    options=df.columns[-1:-3:-1],\n    description='Predict what:',\n    disabled=False,\n    button_style='', # 'success', 'info', 'warning', 'danger' or '',\n#     icons=['check'] * 3\n)\n\n\ndef inference_widgets():\n    global inwidgets, inferbutton, barewidgets, synchrobox, bareboxes\n    \n    inwidgets = []\n    \n    for i, input_variable in enumerate(df.columns):\n        \n        if input_variable == 'Primary Delay per 100 miles':\n            w =HBox([widgets.FloatSlider(min = 0, max = df[input_variable].max()*1.2, value = int(df[58:59][input_variable]), layout=Layout(width='200px'), readout = False,  continuous_update=True, step = 0.2),\n                     widgets.BoundedFloatText(value = int(df[58:59][input_variable]), layout=Layout(width='120px', padding = '0px 10px 0px 10px'), step = 0.2,  readout_format='.3f'),\n                     Label(input_variable),])\n            \n        else:\n            w =HBox([widgets.IntSlider(min = 0, max = df[input_variable].max()*1.2, value = int(df[58:59][input_variable]), layout=Layout(width='200px'), readout = False,  continuous_update=True), \n                     widgets.IntText(value = int(df[58:59][input_variable]), layout=Layout(width='120px', padding = '0px 10px 0px 10px')  ),\n                     Label(input_variable),])\n        \n        widgets.link((w.children[0], 'value'), (w.children[1], 'value'))\n        \n        w.children[0].observe(SliderChanged, 'value')\n        inwidgets.append(w)\n    \n    inwidgets = VBox(inwidgets)\n    barewidgets = [hbox.children[0] for hbox in inwidgets.children]\n    bareboxes = [hbox.children[1] for hbox in inwidgets.children]\n    \n    #for w in inwidgets.children:\n        #SliderChangedFunc = SliderChangedFuncGenerator(w.children[0])\n        #w.children[0].observe(SliderChangedFunc, names = 'value')\n    \n    \n    \n    inferbutton = widgets.Button(description=f\"Predict {labelname}\", layout=Layout(width='200px'))\n    \n    synchrobox = widgets.Checkbox(\n        value=True,\n        description='Synchronise sliders',\n        disabled=False,\n        indent=False,\n        layout=Layout(height='18px', padding = '1px')\n    )\n    \n    \n    inferbutton.on_click(infer)\n    \n    \n    display(inwidgets)\n    display(synchrobox)\n    display(inferbutton)\n    \n    \n\nbutton = widgets.Button(description=\"Generate model\")\n\ndisplay(z)\ndisplay(checkboxes)\ndisplay(buttons)\ndisplay(button)\n\nbutton.on_click(train_and_validate)\n\ntrain_and_validate(None)\n\n#savestamp","execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Label(value='Using these variables:', layout=Layout(height='21px', width='150px'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8276c6d9f7549b6ba7b1866001c55cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Checkbox(value=True, description='Primary Delay per 100 miles', layout=Layout(height='18px', pa…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"401dd01eebbf439b895fcc0f2d75669d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ToggleButtons(description='Predict what:', options=('PPM%', 'On Time WTT%'), value='PPM%')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7936fdd00004614afa186e7a756476e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Generate model', style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"645d65826a6b4fdd941f815ca3b046bf"}},"metadata":{}},{"output_type":"stream","text":"Generating model...\nContaining variables ['Primary Delay per 100 miles', 'Footfall', 'Count of Trains/Timing Points - WTT', 'Planned'] \nTargeting PPM% as output\nCross-validated mean absolute error for model: 1.46%, standard deviation 0.00\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HBox(children=(FloatSlider(value=1.0, layout=Layout(width='200px'), max=11.424, readout=False, …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fabbc6ddb780440a99dfc784e4c06a6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Checkbox(value=True, description='Synchronise sliders', indent=False, layout=Layout(height='18px', padding='1p…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baf8dcffaa0643f58971c5db3973451e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Button(description='Predict PPM%', layout=Layout(width='200px'), style=ButtonStyle())","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca79dbcd778a49ab955a561ef59f5ad3"}},"metadata":{}},{"output_type":"stream","text":"PPM% live Estimate = 82.59%","name":"stdout"}]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"markdown","source":"%matplotlib notebook\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nif False:\n    from ipywidgets import interact, FloatSlider, HBox\n    import ipywidgets as widgets\n    from IPython.display import clear_output, display\n    import sys\n\n    x_widget = FloatSlider(min=0.0, max=10.0, step=0.05)\n    y_widget = FloatSlider(min=0.5, max=10.0, step=0.05, value=5.0)\n\n    def update_x_range(*args):\n        x_widget.value = 2.0 * y_widget.value\n        sys.stdout.flush()\n        print(args, x_widget.value, y_widget.value,  end=\"\\r\", flush=True,)\n\n    def update_y_range(*args):\n        y_widget.value = 0.5 * x_widget.value\n        sys.stdout.flush()\n        print(args, x_widget.value, y_widget.value,  end=\"\\r\", flush=True,)\n        \n    def update_range(change):\n        \n        pass\n\n    y_widget.observe(plot1, 'value')\n    x_widget.observe(update_y_range, 'value')\n\n    def printer(x, y):\n        print(x, y)\n\n    z = HBox([x_widget, y_widget])\n\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    plt.ion()\n\n    fig.show()\n    fig.canvas.draw()\n\n    def plot1(args):\n        ax.clear()\n        ax.plot(np.sin(np.linspace(0,args['new'])))\n        sys.stdout.flush()\n        print(args, x_widget.value, y_widget.value,  end=\"\\r\", flush=True,)\n        fig.canvas.draw()\n    \n    \n    display(z)"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
